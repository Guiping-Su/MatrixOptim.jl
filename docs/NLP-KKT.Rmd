
## KKT Conditions

KKT conditions is the necessary conditions for optimality in general constrained problem.

### for Constrained Optimization with Inequality Constraints

> Satisfying these conditions does not guarantee that the solution is optimal. Certain additional convexity assumptions are needed to obtain this guarantee. [@hillier2012introduction]

Thus, following corollary can be used instead:

```{corollary}
Assume that $f(\mathbf{x})$ is a concave function and that $g_{1}(\mathbf{x}), g_{2}(\mathbf{x}), \ldots, g_{m}(\mathbf{x})$ are convex functions (i.e., this problem is a convex programming problem), where all these functions satisfy the regularity conditions. Then $\mathbf{x}^{*}=\left(x_{1}^{*}, x_{2}^{*}, \ldots, x_{n}^{*}\right)$ is an optimal solution if and only if all the conditions of the theorem are satisfied.
```

#### KKT Example 1: Utility Maximisation {-}

The integrality regrading the bottles is neglected in this part, so the decision variables are defined as follows:
$$ \begin{array}{clc}
\hline
\text { Variables } & \text { Definition } & \text{ Type } \\
\hline
\mathrm{x}_{1} & \text { hours spent producing IPA } & \text{continuous} \\
\mathrm{x}_{2} & \text { hours spent producing Lager } & \text{continuous} \\
\hline
\end{array} $$

The problem can be formulated as:
$$ \begin{align} \begin{split}
    \max \quad & 15 \sqrt{x_{1}} + 16 \sqrt{x_{2}} \\
    \text{s.t.} \quad & x_{1} + x_{2} \leq 120 \\
    & x_{1}, x_{2} \geq 0
\end{split} \end{align} $$

<!-- There exists an optimal solution according to Weierstrass theorem, because The function is continuous, and coercive for maximization (check that objective function increases monotonically when $x_{1}$ or $x_{2}$ increase and there are constraints). Besides, the less equation sign can be replaced by equal sign. -->

The constraint, $x_{1}, x_{2} \geq 0$, is neglected for the time being. Thus the Lagrangian function of the above problem is:
$$ \begin{align} \begin{split}
    L(x_{1}, x_{2}, \lambda) = 15 \sqrt{x_{1}} + 16 \sqrt{x_{2}} - \lambda (x_{1} + x_{2} - 120)
\end{split} \end{align} $$
whose critical points can be calculated following KKT conditions:
$$ \begin{align} \begin{split}
    \frac{\partial L}{\partial x_{1}} &= 15 / 2 \sqrt{x_{1}} - \lambda = 0 \\
    \frac{\partial L}{\partial x_{2}} &= 8 / \sqrt{x_{2}} - \lambda = 0 \\
    \frac{\partial L}{\partial \lambda} &= x_{1} + x_{2} - 120 = 0
\end{split} \end{align} $$

By eliminating $\lambda$, we get:
$$ \begin{align} \begin{split}
    x_{1} &= 56.133 \quad \text{so that  } 3 \sqrt{x_{1}} \approx 22.5 \\
    x_{2} &= 63.867 \quad \text{so that  } 4 \sqrt{x_{2}} \approx 32 \\
    \lambda &\approx 1 \\
    15 \sqrt{x_{1}} + 16 \sqrt{x_{2}} &= 240.250 \\
\end{split} \end{align} $$
which respects the constraint, $x_{1}, x_{2} \geq 0$.

Two parts in the function $L(x_{1}, x_{2}, \lambda)$ are monotonically increasing, so the function is strictly convex because its Hessian matrix is positive semidefinite for all possible values. So the solution (56.133, 63.867) is the global maximum.

So I would allocate 56.133 hours in total to produce 22 and half bottles of IPA, and 63.867 hours in total to produce 32 bottles of Lager. The obtained maximum revenue is 240.250.

### Validation

The results obtained from modern optimisation algorithms can be validated using the duality gap and KKT conditions.

> For complicated problems, it may be difficult, if not essentially impossible, to derive an optimal solution directly from the KKT conditions. Nevertheless, these conditions still provide valuable clues as to the identity of an optimal solution, and they also permit us to check whether a proposed solution may be optimal. [@hillier2012introduction]

### Lagrangian Duality

> There also are many valuable indirect applications of the KKT conditions. One of these applications arises in the duality theory that has been developed for nonlinear programming to parallel the duality theory for linear programming. [@hillier2012introduction]

The basic idea in Lagrangian duality is to take the constraints in (5.1) into account by augmenting the objective function with a weighted sum of the constraint functions.
